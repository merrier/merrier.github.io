<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta http-equiv="Cache-Control" content="no-siteapp"><meta http-equiv="Cache-Control" content="no-transform"><meta name="renderer" content="webkit|ie-comp|ie-stand"><meta name="apple-mobile-web-app-capable" content="Merrier说"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="browsermode" content="application"><meta name="screen-orientation" content="portrait"><link rel="dns-prefetch" href="http://merrier.wang"><meta name="description" content="Merrier的个人博客"><meta name="keywords" content=""><meta name="robots" content="all"><meta name="google" content="all"><meta name="googlebot" content="all"><meta name="verify" content="all"><meta name="google-site-verification" content="UkMBUrF2qTuMWfmPXWFFmc_pnqCRAxHQY1ndE0Zu1p0"><link rel="apple-touch-icon" href="/images/hexo_others_10.png"><title>机器学习概念入门 | Merrier说</title><link rel="alternate" href="/atom.xml" title="Merrier说" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/bootstrap.min.css?rev=9be54fca751d321cf4cde53fe170f6d6"><link rel="stylesheet" href="/css/font-awesome.min.css?rev=d13d6f6bf3dcbaccb347c89baa7f4bd0"><link rel="stylesheet" href="/css/style.css?rev=9a689f858f6a74dab8e5254940cc5a3b"><div class="hide"><script type="text/javascript">var cnzz_protocol="https:"==document.location.protocol?" https://":" http://";document.write(unescape("%3Cspan class='cnzz_stat_icon_1264342320 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='"+cnzz_protocol+"s19.cnzz.com/z_stat.php%3Fid%3D1264342320%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"))</script></div><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script></head></html><!--[if lte IE 8]><style>
    html{ font-size: 1em }
</style><![endif]--><!--[if lte IE 9]><div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div><![endif]--><body><header class="main-header" style="background-image:url(http://snippet.shenliyang.com/img/banner.jpg)"><div class="main-header-box"><a class="header-avatar" href="/" title="Merrier"><img src="/images/hexo_others_8.jpeg" alt="logo头像" class="img-responsive center-block"></a><div class="branding"><h2>叩首问路，码梦为生</h2></div></div></header><nav class="main-navigation"><div class="container"><div class="row"><div class="col-sm-12"><div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav"><span class="sr-only"></span><i class="fa fa-bars"></i></span> <a class="navbar-brand" href="http://merrier.wang">Merrier说</a></div><div class="collapse navbar-collapse" id="main-menu"><ul class="menu"><li role="presentation" class="text-center"><a href="/"><i class="fa fa-home"></i> Home</a></li><li role="presentation" class="text-center"><a href="/categories/frontend/"><i class="fa fa-tablet"></i> 前端</a></li><li role="presentation" class="text-center"><a href="/categories/summary/"><i class="fa fa-diamond"></i> 总结</a></li><li role="presentation" class="text-center"><a href="/categories/talk/"><i class="fa fa-coffee"></i> 杂谈</a></li><li role="presentation" class="text-center"><a href="/categories/series/"><i class="fa fa-shopping-cart"></i> 系列专栏</a></li><li role="presentation" class="text-center"><a href="/archives/"><i class="fa fa-archive"></i> 文章归档</a></li></ul></div></div></div></div></nav><section class="content-wrap"><div class="container"><div class="row"><main class="col-md-8 main-content m-post"><p id="process"></p><article class="post"><div class="post-head"><h1 id="机器学习概念入门">机器学习概念入门</h1><div class="post-meta"><span class="categories-meta fa-wrap"><i class="fa fa-folder-open-o"></i> <a href="/categories/笔记">笔记</a></span><span class="fa-wrap"><i class="fa fa-tags"></i> <span class="tags-meta"><a href="/tags/笔记" title="笔记">笔记</a> <a href="/tags/机器学习" title="机器学习">机器学习</a></span></span><span class="fa-wrap"><i class="fa fa-clock-o"></i> <span class="date-meta">2017/11/02</span></span><span class="fa-wrap"><i class="fa fa-eye"></i><span id="busuanzi_value_page_pv"></span></span></div></div><div class="post-body post-content"><p>最近在做毕设，需要用到一些机器学习的内容（不要问我为什么，做前端根本没办法毕业！），这篇文章是我看 bilibili 上<a href="https://www.bilibili.com/video/av12556478/" target="_blank" rel="noopener">莫烦系列教程-Tensorflow教程</a>时候做的笔记，都是一些机器学习入门概念，如果你和我一样都是入门选手，我相信这些概念能够帮助到你~</p><h2 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h2><p>机器学习是一帮计算机科学家想让计算机像人一样思考，所研发出来的计算机理论</p><h2 id="机器学习分类"><a href="#机器学习分类" class="headerlink" title="机器学习分类"></a>机器学习分类</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>有数据和标签</p><h3 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h3><p>只有数据，没有标签</p><h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>结合了监督学习和非监督学习</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>从经验中总结提升</p><h3 id="遗传算法"><a href="#遗传算法" class="headerlink" title="遗传算法"></a>遗传算法</h3><p>和强化学习类似，有着适者生存，不适者淘汰准则</p><h2 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a>什么是神经网络</h2><p>神经网络是一种数学模型，是存在于计算机的神经系统，由大量的神经元相连接并进行计算，在外界信息的基础上，改变内部的结构，常用来对输入和输出间复杂的关系进行建模。</p><p>神经网络由大量的节点和之间的联系构成，负责传递信息和加工信息，神经元也可以通过训练而被强化。</p><h2 id="怎么检验神经网络"><a href="#怎么检验神经网络" class="headerlink" title="怎么检验神经网络"></a>怎么检验神经网络</h2><p>为了检验、评价神经网络，并努力改善这些问题，我们常会把收集到的数据分为<strong>训练数据</strong>和<strong>测试数据</strong>，一般用于训练的数据可以是全部数据的百分之 70，剩下的百分之 30 可以用来测试学习结果。接着，对于神经网络的评价，基本上基于这百分之 30 的测试结果。</p><ul><li>评价机器学习可以从误差这个值开始，随着训练时间的变长，优秀的神经网络能够预测到更精准的答案，预测的误差也会越小；</li><li>除了误差曲线，我们也可以看它的精确度曲线，最好的精度是趋向于百分之百的精度；</li><li>对于回归问题，我们可以采用 R2 score 作为评分标准；</li><li>还有 F1 score 用来测量不均衡数据的精度。</li></ul><h2 id="什么叫过拟合"><a href="#什么叫过拟合" class="headerlink" title="什么叫过拟合"></a>什么叫过拟合</h2><p>如下图，训练时的误差比测试误差小，神经网络虽然学习到了知识，但是对于训练数据太过依赖，所以测试数据产生的误差会产生波谷，后面会变大。</p><div align="center"><img src="/images/hexo_post_287.png" alt="" width="400"></div><p>在机器学习中，解决过拟合的方法也有很多，比如 <strong>L1，L2正规化</strong>和 <strong>Dropout方法</strong></p><h2 id="什么是交叉验证"><a href="#什么是交叉验证" class="headerlink" title="什么是交叉验证"></a>什么是交叉验证</h2><p>交叉验证不仅可以用于神经网络的调参，还可以用于其他机器学习方法的调参，同样是选择你想观看的误差值或者精确度，不过横坐标不再是学习时间，而是你要测试的某一参数，比如说神经网络的层数。。</p><h2 id="为什么要特征标准化"><a href="#为什么要特征标准化" class="headerlink" title="为什么要特征标准化"></a>为什么要特征标准化</h2><p>我们在机器学习训练之前, 先对数据预先处理一下, 取值跨度大的特征数据, 我们浓缩一下, 跨度小的括展一下, 使得他们的跨度尽量统一，这样可以<strong>提升学习效率</strong> 通常用于 特征标准化的途径有两种, 一种叫做 min max normalization, 他会将所有特征数据按比例缩放到 0-1 的这个取值区间. 有时也可以是 -1 到 1 的区间. 还有一种叫做 standard deviation normalization, 他会将所有特征数据缩放成平均值为 0, 方差为 1. 使用这些标准化手段. 我们不仅可以快速推进机器学习的学习速度, 还可以<strong>避免机器学习学得特扭曲</strong>.</p><h2 id="区分好用的特征"><a href="#区分好用的特征" class="headerlink" title="区分好用的特征"></a>区分好用的特征</h2><p>在选择特征的时候,我们得要时刻回想起这三点.：</p><ol><li>避免无意义的信息</li><li>避免重复性的信息</li><li>避免复杂的信息</li></ol><p>这就是我们这次机器学习简介中所聊到的如何区分好用的特征</p><h2 id="为什么需要激励函数"><a href="#为什么需要激励函数" class="headerlink" title="为什么需要激励函数"></a>为什么需要激励函数</h2><p>因为现实中的问题往往不是线性的，所以需要一个激励函数<strong>来扭曲原来的线性结果</strong> 你甚至可以创造自己的激励函数来处理自己的问题, 不过要确保的是这些激励函数必须是可以微分的, 因为在 backpropagation 误差反向传递的时候, 只有这些可微分的激励函数才能把误差传递回去. 在少量层结构中, 我们可以尝试很多种不同的激励函数. 在卷积神经网络 Convolutional neural networks 的卷积层中, 推荐的激励函数是 relu. 在循环神经网络中 recurrent neural networks, 推荐的是 tanh 或者是 relu</p><h2 id="如何加速神经网络训练"><a href="#如何加速神经网络训练" class="headerlink" title="如何加速神经网络训练"></a>如何加速神经网络训练</h2><p>越复杂的神经网络，越多的数据，我们需要在训练神经网络的过程上花费的时间也就越多；原因很简单，就是因为计算量太大了。可是往往有时候为了解决复杂的问题, 复杂的结构和大数据又是不能避免的, 所以我们需要寻找一些方法, 让神经网络聪明起来, 快起来. 包括以下几种模式:</p><ul><li>Stochastic Gradient Descent (SGD)</li><li>Momentum</li><li>AdaGrad</li><li>RMSProp</li><li>Adam</li></ul><p>关于这几种方法的具体原理，可以<a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/" target="_blank" rel="noopener">点击这里</a>观看莫烦的讲解</p><h2 id="如何处理不均衡数据"><a href="#如何处理不均衡数据" class="headerlink" title="如何处理不均衡数据"></a>如何处理不均衡数据</h2><p>不均衡的数据预测起来很简单. 永远都猜多的那一方面准没错. 没错, 机器也懂这个小伎俩. 所以机器学到最后, 学乖了, 每次都预测多数派. 解决的方法有几种, 我们来谈谈.</p><h3 id="方法一：想办法获取更多数据"><a href="#方法一：想办法获取更多数据" class="headerlink" title="方法一：想办法获取更多数据"></a>方法一：想办法获取更多数据</h3><h3 id="方法二：更换评判方式"><a href="#方法二：更换评判方式" class="headerlink" title="方法二：更换评判方式"></a>方法二：更换评判方式</h3><p>通常, 我们会用到准确率 accuracy, 或者误差 cost 来判断机器学习的成果. 可是这些评判方法在不均衡数据面前, 高的准确率和低的误差变得没那么重要. 所以我们得换一种方式评判. 通过 confusion matrix 来计算 precision 和 recall, 然后通过 precision 和 recall 再计算f1 score.这种方式能成功地区分不均衡数据, 给出更好的评判分数.</p><h3 id="方法三：重组数据"><a href="#方法三：重组数据" class="headerlink" title="方法三：重组数据"></a>方法三：重组数据</h3><p>这是最简单粗暴的方法之一，重新组合不均衡数据，使之均衡。有两种方式：</p><ol><li>复制或者合成少数部分的样本, 使之和多数部分差不多数量</li><li>砍掉一些多数部分, 使两者数量差不多</li></ol><h3 id="方法四：使用其他机器学习方法"><a href="#方法四：使用其他机器学习方法" class="headerlink" title="方法四：使用其他机器学习方法"></a>方法四：使用其他机器学习方法</h3><p>如果使用的机器学习方法像神经网络等, 在面对不均衡数据时, 通常是束手无策. 不过有些机器学习方法, 像决策树, decision trees 就不会受到不均很数据的影响.</p><h3 id="方法五：修改算法"><a href="#方法五：修改算法" class="headerlink" title="方法五：修改算法"></a>方法五：修改算法</h3><p>最后一种方法是让自己变得有创造力, 尝试修改算法. 如果你用的是 Sigmoid 的激励函数, activation function, 他会有一个<strong>预测门槛</strong>, 一般如果输出结果落在门槛的这一段,预测结果为梨, 如果落在这一段, 预测结果为苹果, 不过因为现在的梨是多数派, 我们得<strong>调整一下门槛的位置，</strong>使得门槛偏向苹果这边, 只有很自信的时候, 模型才会预测这是苹果. 让机器学习,学习到更好的效果.</p><h2 id="什么是批标准化"><a href="#什么是批标准化" class="headerlink" title="什么是批标准化"></a>什么是批标准化</h2><p>和普通的数据标准化类似, 是将分散的数据统一的一种做法, 也是优化神经网络的一种方法. Batch normalization 的 batch 是批数据, <strong>把数据分成小批小批进行 stochastic gradient descent. 而且在每批数据进行前向传递 forward propagation 的时候, 对每一层都进行 normalization 的处理</strong> Batch normalization 也可以被看做一个层面. 在一层层的添加神经网络的时候, 我们先有数据 X, 再添加全连接层, 全连接层的计算结果会经过 激励函数 成为下一层的输入, 接着重复之前的操作. Batch Normalization (BN) 就被添加在每一个全连接和激励函数之间。</p><h2 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h2><ul><li><a href="https://www.jianshu.com/p/e112012a4b2d" target="_blank" rel="noopener">一文学会用 Tensorflow 搭建神经网络</a></li></ul></div><div class="reward"><div class="reward-wrap">赏<div class="reward-box"><span class="reward-type"><img class="alipay" src="/images/hexo_others_5.png"><b>支付宝打赏</b></span> <span class="reward-type"><img class="wechat" src="/images/hexo_others_6.png"><b>微信打赏</b></span></div></div><p class="reward-tip">听说赞过就能年薪百万</p></div><div class="post-footer"><div>转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="//merrier.wang" target="_blank">Merrier说</a></div><div></div></div></article><div class="article-nav prev-next-wrap clearfix"><a href="/20171107/comments-on-netease-cloud-music.html" class="pre-post btn btn-default" title="是时候为网易云音乐的评论打call了"><i class="fa fa-angle-left fa-fw"></i> <span class="hidden-lg">上一篇</span> <span class="hidden-xs">是时候为网易云音乐的评论打call了</span></a> <a href="/20171017/why-i-write-blog.html" class="next-post btn btn-default" title="我为什么要写个人博客"><span class="hidden-lg">下一篇</span> <span class="hidden-xs">我为什么要写个人博客</span><i class="fa fa-angle-right fa-fw"></i></a></div><div id="comments"><script id="dsq-count-scr" src="https://merrier.disqus.com/count.js" async></script><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script type="text/javascript">if(document.getElementById("disqus_thread")){var disqus_config=function(){this.page.url="http://merrier.wang/20171102/introduction-to-machine-learning-concept.html",this.page.identifier="20171102/introduction-to-machine-learning-concept.html",this.page.title="机器学习概念入门"};!function(){var t=document,e=t.createElement("script");e.async=!0,e.src="https://merrier.disqus.com/embed.js",e.setAttribute("data-timestamp",""+ +new Date),(t.head||t.body).appendChild(e)}()}</script></div></main><aside id="article-toc" role="navigation" class="col-md-4"><div class="widget"><h3 class="title">文章目录</h3><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是机器学习"><span class="toc-text">什么是机器学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#机器学习分类"><span class="toc-text">机器学习分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#监督学习"><span class="toc-text">监督学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#非监督学习"><span class="toc-text">非监督学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#半监督学习"><span class="toc-text">半监督学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#强化学习"><span class="toc-text">强化学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#遗传算法"><span class="toc-text">遗传算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是神经网络"><span class="toc-text">什么是神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#怎么检验神经网络"><span class="toc-text">怎么检验神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#什么叫过拟合"><span class="toc-text">什么叫过拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是交叉验证"><span class="toc-text">什么是交叉验证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么要特征标准化"><span class="toc-text">为什么要特征标准化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#区分好用的特征"><span class="toc-text">区分好用的特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么需要激励函数"><span class="toc-text">为什么需要激励函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何加速神经网络训练"><span class="toc-text">如何加速神经网络训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何处理不均衡数据"><span class="toc-text">如何处理不均衡数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方法一：想办法获取更多数据"><span class="toc-text">方法一：想办法获取更多数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方法二：更换评判方式"><span class="toc-text">方法二：更换评判方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方法三：重组数据"><span class="toc-text">方法三：重组数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方法四：使用其他机器学习方法"><span class="toc-text">方法四：使用其他机器学习方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方法五：修改算法"><span class="toc-text">方法五：修改算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是批标准化"><span class="toc-text">什么是批标准化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#扩展阅读"><span class="toc-text">扩展阅读</span></a></li></ol></div></aside></div></div></section><footer class="main-footer"><div class="container"><div class="row"></div></div></footer><a id="back-to-top" class="icon-btn hide"><i class="fa fa-chevron-up"></i></a><div class="copyright"><div class="container"><div class="row"><div class="col-sm-12"><div class="busuanzi">访问量:<strong id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></strong> &nbsp; | &nbsp; 访客数:<strong id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></strong></div></div><div class="col-sm-12"><span>Copyright &copy; 2018</span> | <span>Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a></span> | <span>Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a></span> | <span>ICP 证： <a href="http://www.beian.miit.gov.cn/" class="copyright-links" target="_blank" rel="nofollow">京ICP备17022347号</a></span></div></div></div></div><script src="/assets/tagcanvas.min.js?rev=d3e34a34636b6f4c81d2b43b153907bb"></script><script>var tagOption={textColour:"#444",outlineMethod:"block",outlineColour:"#FFDAB9",interval:30,textHeight:13,outlineRadius:3,freezeActive:!0,frontSelect:!0,initial:[.1,-.1],depth:.5,decel:.95,maxSpeed:.03,reverse:!0,fadeIn:500,wheelZoom:!0};TagCanvas.Start("tag-cloud-3d","",tagOption)</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/app.js?rev=26a1b6fecd389c0121b7027a299aa7c0"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!0,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{superSample:2,width:125,height:125,position:"right",hOffset:30,vOffset:0},mobile:{show:!1,scale:.05},react:{opacityDefault:1,opacityOnHover:.2},log:!1})</script></body>